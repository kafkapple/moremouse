# MoReMouse Pipeline Overview

> ë‹¨ì•ˆ ì´ë¯¸ì§€ì—ì„œ ì‹¤í—˜ìš© ìƒì¥ì˜ 3D ì¬êµ¬ì„±ì„ ìœ„í•œ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì„¤ëª…

---

## ëª©ì°¨
1. [ì „ì²´ ì•„í‚¤í…ì²˜](#1-ì „ì²´-ì•„í‚¤í…ì²˜)
2. [Stage 1: Gaussian Mouse Avatar (AGAM)](#2-stage-1-gaussian-mouse-avatar-agam)
3. [Stage 2: í•©ì„± ë°ì´í„° ìƒì„±](#3-stage-2-í•©ì„±-ë°ì´í„°-ìƒì„±)
4. [Stage 3: MoReMouse ë„¤íŠ¸ì›Œí¬](#4-stage-3-moremouse-ë„¤íŠ¸ì›Œí¬)
5. [Stage 4: DMTet ë©”ì‰¬ ì¶”ì¶œ](#5-stage-4-dmtet-ë©”ì‰¬-ì¶”ì¶œ)
6. [í•™ìŠµ ì„¤ì • (Paper)](#6-í•™ìŠµ-ì„¤ì •-paper)

---

## 1. ì „ì²´ ì•„í‚¤í…ì²˜

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          MoReMouse Pipeline                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Multi-view  â”‚â”€â”€â”€â–¶â”‚   Gaussian   â”‚â”€â”€â”€â–¶â”‚   Synthetic  â”‚â”€â”€â”€â–¶â”‚ MoReMouse â”‚  â”‚
â”‚  â”‚    Videos    â”‚    â”‚    Avatar    â”‚    â”‚     Data     â”‚    â”‚  Network  â”‚  â”‚
â”‚  â”‚   (8 cams)   â”‚    â”‚   (AGAM)     â”‚    â”‚  (12K scenes)â”‚    â”‚           â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                     â”‚        â”‚
â”‚                                                                     â–¼        â”‚
â”‚                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚                           â”‚   Inference  â”‚â—€â”€â”€â”€â”‚  NeRF â†’ DMTet â†’ Mesh     â”‚  â”‚
â”‚                           â”‚  (ë‹¨ì•ˆ ì´ë¯¸ì§€)â”‚    â”‚  (Density â†’ SDF â†’ Mesh)  â”‚  â”‚
â”‚                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### í•µì‹¬ ì•„ì´ë””ì–´
1. **ë¬¸ì œ**: ë‹¨ì•ˆ(monocular) ì´ë¯¸ì§€ì—ì„œ 3D ì¬êµ¬ì„±ì€ ill-posed problem
2. **í•´ê²°ì±…**:
   - Multi-view ë°ì´í„°ë¡œ photorealistic avatar í•™ìŠµ
   - Avatarë¡œ ëŒ€ê·œëª¨ í•©ì„± ë°ì´í„° ìƒì„± (ë‹¤ì–‘í•œ pose, viewpoint)
   - í•©ì„± ë°ì´í„°ë¡œ ë‹¨ì•ˆâ†’3D ë„¤íŠ¸ì›Œí¬ í•™ìŠµ

---

## 2. Stage 1: Gaussian Mouse Avatar (AGAM)

### 2.1 ëª©ì 
Multi-view ë¹„ë””ì˜¤ì—ì„œ **í¬í† ë¦¬ì–¼ë¦¬ìŠ¤í‹±í•œ ìƒì¥ ì•„ë°”íƒ€**ë¥¼ í•™ìŠµí•˜ì—¬, ì´í›„ í•©ì„± ë°ì´í„° ìƒì„±ì— ì‚¬ìš©

### 2.2 ì…ë ¥ ë°ì´í„°
```
/home/joon/data/markerless_mouse_1_nerf/
â”œâ”€â”€ videos_undist/
â”‚   â”œâ”€â”€ 0.mp4      # Camera 0 (ë™ê¸°í™”ëœ multi-view)
â”‚   â”œâ”€â”€ 1.mp4      # Camera 1
â”‚   â”œâ”€â”€ ...
â”‚   â””â”€â”€ 5.mp4      # Camera 5 (ì´ 6ëŒ€)
â””â”€â”€ calibration/   # ì¹´ë©”ë¼ ìº˜ë¦¬ë¸Œë ˆì´ì…˜
```

### 2.3 MAMMAL Body Model
```python
# 140ê°œ ê´€ì ˆì„ ê°€ì§„ Articulated Mouse Model
body_model = load_mouse_model("mouse_model/mouse.pkl")
# - v_template: [13059, 3] ê¸°ë³¸ ë©”ì‰¬ ì •ì 
# - faces: [25350, 3] ì‚¼ê°í˜• ë©´
# - skinning_weights: [13059, 140] LBS ê°€ì¤‘ì¹˜
# - joint_regressor: ê´€ì ˆ ìœ„ì¹˜ ê³„ì‚°
```

### 2.4 Gaussian Splatting on UV Space

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Gaussian Avatar Architecture                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚   UV Space (Learnable)              3D Space (Rendered)         â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚   â”‚  â—‹ â—‹ â—‹ â—‹ â—‹ â—‹   â”‚   Deform      â”‚                 â”‚         â”‚
â”‚   â”‚  â—‹ â—‹ â—‹ â—‹ â—‹ â—‹   â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â–¶    â”‚    â”Œâ”€â”€â”€â”€â”€â”      â”‚         â”‚
â”‚   â”‚  â—‹ â—‹ â—‹ â—‹ â—‹ â—‹   â”‚   (LBS)       â”‚   /  â—    \     â”‚         â”‚
â”‚   â”‚  â—‹ â—‹ â—‹ â—‹ â—‹ â—‹   â”‚               â”‚  â”‚   â—â—    â”‚    â”‚         â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚   \______/     â”‚         â”‚
â”‚   Gaussians per vertex              â”‚  3D Gaussians  â”‚         â”‚
â”‚                                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                                                                  â”‚
â”‚   Parameters per Gaussian:                                       â”‚
â”‚   - position offset (Î”x, Î”y, Î”z): ë©”ì‰¬ ì •ì  ê¸°ì¤€ ì˜¤í”„ì…‹         â”‚
â”‚   - scale (sx, sy, sz): Gaussian í¬ê¸°                           â”‚
â”‚   - rotation (quaternion): Gaussian ë°©í–¥                        â”‚
â”‚   - opacity (Î±): ë¶ˆíˆ¬ëª…ë„                                       â”‚
â”‚   - color (SH coefficients): ë·° ì˜ì¡´ì  ìƒ‰ìƒ                     â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.5 Linear Blend Skinning (LBS)

í¬ì¦ˆì— ë”°ë¼ Gaussian ìœ„ì¹˜ë¥¼ ë³€í˜•:

```python
def forward_lbs(vertices, pose, skinning_weights, joint_transforms):
    """
    vertices: [V, 3] - ì •ì  ìœ„ì¹˜
    pose: [J, 3] - ê´€ì ˆ íšŒì „ (axis-angle)
    skinning_weights: [V, J] - ê° ì •ì ì´ ê° ê´€ì ˆì— ì˜í–¥ë°›ëŠ” ì •ë„

    Returns: [V, 3] - ë³€í˜•ëœ ì •ì  ìœ„ì¹˜
    """
    # 1. Pose â†’ Joint Transforms (4x4 matrices)
    # 2. Blend transforms: T_blended = Î£ w_j * T_j
    # 3. Apply: v' = T_blended @ v
```

### 2.6 ë Œë”ë§ (gsplat)

```python
# Differentiable Gaussian Splatting
rendered_image = rasterization(
    means=gaussian_positions,      # [N, 3] 3D ìœ„ì¹˜
    quats=gaussian_rotations,      # [N, 4] íšŒì „
    scales=gaussian_scales,        # [N, 3] ìŠ¤ì¼€ì¼
    opacities=gaussian_opacities,  # [N, 1] ë¶ˆíˆ¬ëª…ë„
    colors=gaussian_colors,        # [N, 3] or [N, SH_dim] ìƒ‰ìƒ
    viewmats=camera_extrinsics,    # [4, 4] ì¹´ë©”ë¼ ì™¸ë¶€ íŒŒë¼ë¯¸í„°
    Ks=camera_intrinsics,          # [3, 3] ì¹´ë©”ë¼ ë‚´ë¶€ íŒŒë¼ë¯¸í„°
)
```

### 2.7 í•™ìŠµ ì†ì‹¤ í•¨ìˆ˜

```python
L_total = L_rgb + Î»_ssim * L_ssim + Î»_lpips * L_lpips

# L_rgb: L1 í”½ì…€ ì†ì‹¤
L_rgb = |I_rendered - I_gt|

# L_ssim: êµ¬ì¡°ì  ìœ ì‚¬ë„ (íŒ¨ì¹˜ ê¸°ë°˜)
L_ssim = 1 - SSIM(I_rendered, I_gt)

# L_lpips: ì§€ê°ì  ì†ì‹¤ (VGG features)
L_lpips = ||VGG(I_rendered) - VGG(I_gt)||
```

---

## 3. Stage 2: í•©ì„± ë°ì´í„° ìƒì„±

### 3.1 ëª©ì 
í•™ìŠµëœ Avatarë¥¼ ì‚¬ìš©í•˜ì—¬ **ëŒ€ê·œëª¨ (pose, viewpoint) ìŒ** ìƒì„±

### 3.2 ë°ì´í„° ìƒì„± ê³¼ì •

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Synthetic Data Generation                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  For each scene (12,000 total):                                 â”‚
â”‚                                                                  â”‚
â”‚  1. Sample Random Pose                                          â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                        â”‚
â”‚     â”‚ pose ~ P(poses)  â”‚  â† MAMMAL fitting ê²°ê³¼ì—ì„œ ìƒ˜í”Œë§      â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    ë˜ëŠ” ëœë¤ augmentation              â”‚
â”‚              â”‚                                                   â”‚
â”‚              â–¼                                                   â”‚
â”‚  2. Deform Avatar (LBS)                                         â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                        â”‚
â”‚     â”‚ Avatar(pose) â†’ â”‚  â† Gaussian positions ë³€í˜•              â”‚
â”‚     â”‚ Posed Gaussians â”‚                                         â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                        â”‚
â”‚              â”‚                                                   â”‚
â”‚              â–¼                                                   â”‚
â”‚  3. Render Multi-view (64 views per scene)                      â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚     â”‚  View 1   View 2   ...   View 64         â”‚                â”‚
â”‚     â”‚  â”Œâ”€â”€â”€â”    â”Œâ”€â”€â”€â”          â”Œâ”€â”€â”€â”           â”‚                â”‚
â”‚     â”‚  â”‚ ğŸ­â”‚    â”‚ ğŸ­â”‚          â”‚ ğŸ­â”‚           â”‚                â”‚
â”‚     â”‚  â””â”€â”€â”€â”˜    â””â”€â”€â”€â”˜          â””â”€â”€â”€â”˜           â”‚                â”‚
â”‚     â”‚  Î¸=0Â°    Î¸=5.6Â°        Î¸=354.4Â°         â”‚                â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚                                                                  â”‚
â”‚  Output per scene:                                               â”‚
â”‚  - images: [64, H, W, 3]     ë Œë”ë§ëœ ì´ë¯¸ì§€                    â”‚
â”‚  - cameras: [64, 4, 4]       ì¹´ë©”ë¼ íŒŒë¼ë¯¸í„°                    â”‚
â”‚  - mesh: [V, 3]              GT ë©”ì‰¬ (from body model)          â”‚
â”‚  - pose: [J*3]               MAMMAL pose                        â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.3 ì¹´ë©”ë¼ ìƒ˜í”Œë§

```python
def sample_cameras(num_views=64, radius=2.22, elevation_range=(-30, 60)):
    """
    êµ¬ í‘œë©´ì—ì„œ ê· ë“±í•˜ê²Œ ì¹´ë©”ë¼ ìœ„ì¹˜ ìƒ˜í”Œë§

    - Azimuth: 0Â° ~ 360Â° (ê· ë“± ë¶„í• )
    - Elevation: -30Â° ~ 60Â° (ëœë¤ ìƒ˜í”Œë§)
    - ëª¨ë“  ì¹´ë©”ë¼ëŠ” ì›ì (ìƒì¥ ì¤‘ì‹¬)ì„ ë°”ë¼ë´„
    """
```

---

## 4. Stage 3: MoReMouse ë„¤íŠ¸ì›Œí¬

### 4.1 ëª©ì 
ë‹¨ì•ˆ ì´ë¯¸ì§€ â†’ 3D NeRF representation í•™ìŠµ

### 4.2 ë„¤íŠ¸ì›Œí¬ ì•„í‚¤í…ì²˜

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    MoReMouse Network                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  Input Image          Encoder              Triplane Features    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚         â”‚         â”‚         â”‚          â”‚  XY   XZ   YZ   â”‚   â”‚
â”‚  â”‚   ğŸ­    â”‚ â”€â”€â”€â”€â”€â”€â–¶ â”‚  DINOv2 â”‚ â”€â”€â”€â”€â”€â”€â–¶  â”‚  â”Œâ”€â”  â”Œâ”€â”  â”Œâ”€â”  â”‚   â”‚
â”‚  â”‚         â”‚         â”‚ + Neck  â”‚          â”‚  â””â”€â”˜  â””â”€â”˜  â””â”€â”˜  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚  [B, 3, H, W]        [B, C, h, w]               [B, 3, C, h, w] â”‚
â”‚                                                     â”‚           â”‚
â”‚                                                     â–¼           â”‚
â”‚                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚                      â”‚         NeRF Decoder                 â”‚   â”‚
â”‚                      â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚   â”‚
â”‚                      â”‚  â”‚ For each 3D point (x, y, z):    â”‚ â”‚   â”‚
â”‚                      â”‚  â”‚                                  â”‚ â”‚   â”‚
â”‚                      â”‚  â”‚ 1. Sample triplane features:     â”‚ â”‚   â”‚
â”‚                      â”‚  â”‚    f_xy = F_xy[x, y]            â”‚ â”‚   â”‚
â”‚                      â”‚  â”‚    f_xz = F_xz[x, z]            â”‚ â”‚   â”‚
â”‚                      â”‚  â”‚    f_yz = F_yz[y, z]            â”‚ â”‚   â”‚
â”‚                      â”‚  â”‚                                  â”‚ â”‚   â”‚
â”‚                      â”‚  â”‚ 2. Aggregate: f = f_xy+f_xz+f_yzâ”‚ â”‚   â”‚
â”‚                      â”‚  â”‚                                  â”‚ â”‚   â”‚
â”‚                      â”‚  â”‚ 3. MLP â†’ (density Ïƒ, color c)   â”‚ â”‚   â”‚
â”‚                      â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚   â”‚
â”‚                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                          â”‚                      â”‚
â”‚                                          â–¼                      â”‚
â”‚                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚                      â”‚       Volume Rendering               â”‚   â”‚
â”‚                      â”‚  I(r) = Î£ T_i Â· Î±_i Â· c_i           â”‚   â”‚
â”‚                      â”‚  where T_i = Î (1 - Î±_j) for j < i   â”‚   â”‚
â”‚                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4.3 DINOv2 Encoder

```python
# Self-supervised Vision Transformer (pretrained)
class DINOv2Encoder(nn.Module):
    def __init__(self):
        self.dino = torch.hub.load('facebookresearch/dinov2', 'dinov2_vitb14')
        # Output: [B, 768, H/14, W/14] patch features

    def forward(self, x):
        features = self.dino.forward_features(x)
        return features  # Rich semantic features
```

### 4.4 Triplane Representation

```python
# 3Dë¥¼ ì„¸ ê°œì˜ 2D í‰ë©´ìœ¼ë¡œ í‘œí˜„ (ë©”ëª¨ë¦¬ íš¨ìœ¨ì )
class TriplaneGenerator(nn.Module):
    def __init__(self, in_channels=768, plane_channels=32, plane_resolution=256):
        self.to_planes = nn.Conv2d(in_channels, plane_channels * 3, 1)

    def forward(self, features):
        # features: [B, C, h, w] from encoder
        planes = self.to_planes(features)  # [B, 3*C', h, w]
        planes = planes.reshape(B, 3, C', h, w)  # [B, 3, C', h, w]
        # planes[0]: XY plane, planes[1]: XZ plane, planes[2]: YZ plane
        return planes
```

### 4.5 NeRF Volume Rendering

```python
def volume_render(density, color, z_vals, rays_d):
    """
    density: [B, N_rays, N_samples] - ë°€ë„ Ïƒ
    color: [B, N_rays, N_samples, 3] - RGB ìƒ‰ìƒ
    z_vals: [B, N_rays, N_samples] - ìƒ˜í”Œë§ ê¹Šì´

    Returns:
        rgb: [B, N_rays, 3] - ë Œë”ë§ëœ ìƒ‰ìƒ
        depth: [B, N_rays] - ì˜ˆì¸¡ ê¹Šì´
    """
    # 1. ê°„ê²© ê³„ì‚°
    dists = z_vals[..., 1:] - z_vals[..., :-1]

    # 2. Alpha ê³„ì‚°: Î± = 1 - exp(-Ïƒ * Î”t)
    alpha = 1 - torch.exp(-density * dists)

    # 3. Transmittance: T = Î (1 - Î±)
    T = torch.cumprod(1 - alpha + 1e-10, dim=-1)

    # 4. Weights: w = T * Î±
    weights = alpha * T

    # 5. RGB í•©ì„±: C = Î£ w_i * c_i
    rgb = (weights[..., None] * color).sum(dim=-2)

    # 6. Depth: D = Î£ w_i * t_i
    depth = (weights * z_vals).sum(dim=-1)

    return rgb, depth, weights
```

### 4.6 NeRF í•™ìŠµ ì†ì‹¤

```python
L_nerf = L_rgb + Î»_depth * L_depth + Î»_mask * L_mask

# RGB ì†ì‹¤ (novel view synthesis)
L_rgb = ||I_pred - I_gt||_1

# Depth ì†ì‹¤ (ê¸°í•˜í•™ì  ì •í™•ë„)
L_depth = ||D_pred - D_gt||_1

# Mask ì†ì‹¤ (ì‹¤ë£¨ì—£ ì¼ì¹˜)
L_mask = BCE(M_pred, M_gt)
```

---

## 5. Stage 4: DMTet ë©”ì‰¬ ì¶”ì¶œ

### 5.1 ëª©ì 
NeRFì˜ implicit density â†’ explicit mesh ë³€í™˜

### 5.2 DMTet (Deep Marching Tetrahedra)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    NeRF â†’ DMTet â†’ Mesh                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  Step 1: Density â†’ SDF ë³€í™˜                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚                                                          â”‚    â”‚
â”‚  â”‚  NeRF Density Ïƒ(x)        SDF s(x)                      â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚    â”‚
â”‚  â”‚  â”‚ â–‘â–‘â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘  â”‚  â”€â”€â”€â”€â”€â”€â–¶ â”‚ â”€â”€â”€â”€â”€0â”€â”€â”€â”€â”€ â”‚               â”‚    â”‚
â”‚  â”‚  â”‚ â–‘â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘  â”‚  MLP     â”‚ â”€â”€0â”€â”€â”€â”€â”€â”€â”€â”€  â”‚               â”‚    â”‚
â”‚  â”‚  â”‚ â–‘â–‘â–‘â–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘  â”‚          â”‚ â”€â”€â”€â”€0â”€â”€â”€â”€â”€â”€â”€ â”‚               â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚    â”‚
â”‚  â”‚  (volume density)         (signed distance)              â”‚    â”‚
â”‚  â”‚                                                          â”‚    â”‚
â”‚  â”‚  SDF ì •ì˜:                                               â”‚    â”‚
â”‚  â”‚  - s(x) < 0: í‘œë©´ ë‚´ë¶€                                   â”‚    â”‚
â”‚  â”‚  - s(x) = 0: í‘œë©´ ìœ„ (zero level set)                    â”‚    â”‚
â”‚  â”‚  - s(x) > 0: í‘œë©´ ì™¸ë¶€                                   â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                  â”‚
â”‚  Step 2: Tetrahedral Grid                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚                                                          â”‚    â”‚
â”‚  â”‚  3D ê³µê°„ì„ ì‚¬ë©´ì²´(tetrahedra)ë¡œ ë¶„í•                      â”‚    â”‚
â”‚  â”‚                                                          â”‚    â”‚
â”‚  â”‚       v1 â—â”€â”€â”€â”€â”€â”€â”€â— v2                                    â”‚    â”‚
â”‚  â”‚         /\      /                                        â”‚    â”‚
â”‚  â”‚        /  \    /                                         â”‚    â”‚
â”‚  â”‚       /    \  /                                          â”‚    â”‚
â”‚  â”‚   v0 â—â”€â”€â”€â”€â”€â”€â—/ v3                                        â”‚    â”‚
â”‚  â”‚                                                          â”‚    â”‚
â”‚  â”‚  ê° vertexì—ì„œ SDF ê°’ ê³„ì‚°: s(v0), s(v1), s(v2), s(v3)  â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                  â”‚
â”‚  Step 3: Marching Tetrahedra                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚                                                          â”‚    â”‚
â”‚  â”‚  SDF ë¶€í˜¸ê°€ ë°”ë€ŒëŠ” edgeì—ì„œ í‘œë©´ vertex ìƒì„±             â”‚    â”‚
â”‚  â”‚                                                          â”‚    â”‚
â”‚  â”‚  Case: v0, v1 < 0 (inside), v2, v3 > 0 (outside)        â”‚    â”‚
â”‚  â”‚                                                          â”‚    â”‚
â”‚  â”‚       v1 â—â”€â”€â”€â”€â”€â”€â”€â— v2                                    â”‚    â”‚
â”‚  â”‚         /\  â—†â—†â—† /      â—† = surface vertices             â”‚    â”‚
â”‚  â”‚        / â—†â—†â—†â—†â—†/                                         â”‚    â”‚
â”‚  â”‚       / â—†â—†  â—†/                                          â”‚    â”‚
â”‚  â”‚   v0 â—â”€â”€â”€â”€â”€â”€â—/ v3                                        â”‚    â”‚
â”‚  â”‚                                                          â”‚    â”‚
â”‚  â”‚  Edge intersection: p = v_a + t*(v_b - v_a)             â”‚    â”‚
â”‚  â”‚  where t = s(v_a) / (s(v_a) - s(v_b))                   â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                  â”‚
â”‚  Step 4: Differentiable Rendering                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚                                                          â”‚    â”‚
â”‚  â”‚  ì¶”ì¶œëœ meshë¥¼ differentiableí•˜ê²Œ ë Œë”ë§                 â”‚    â”‚
â”‚  â”‚  â†’ RGB/Silhouette lossë¡œ SDF íŒŒë¼ë¯¸í„° ìµœì í™”             â”‚    â”‚
â”‚  â”‚                                                          â”‚    â”‚
â”‚  â”‚  DMTet ì¥ì :                                             â”‚    â”‚
â”‚  â”‚  - Marching Cubesë³´ë‹¤ ì ì€ ì•„í‹°íŒ©íŠ¸                      â”‚    â”‚
â”‚  â”‚  - End-to-end differentiable                             â”‚    â”‚
â”‚  â”‚  - Topology ë³€í™” ê°€ëŠ¥                                    â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 5.3 DMTet í•™ìŠµ

```python
class DMTetStage(nn.Module):
    def __init__(self, nerf_model, grid_resolution=128):
        self.nerf = nerf_model  # Frozen or fine-tuned
        self.sdf_mlp = nn.Sequential(
            nn.Linear(nerf_feature_dim, 128),
            nn.ReLU(),
            nn.Linear(128, 1)  # SDF value
        )
        self.deform_mlp = nn.Sequential(
            nn.Linear(nerf_feature_dim, 128),
            nn.ReLU(),
            nn.Linear(128, 3)  # Vertex offset
        )

    def forward(self, image, camera):
        # 1. NeRF features ì¶”ì¶œ
        triplane = self.nerf.encode(image)

        # 2. Grid pointsì—ì„œ SDF ì˜ˆì¸¡
        sdf = self.predict_sdf(triplane, grid_points)

        # 3. Marching tetrahedraë¡œ mesh ì¶”ì¶œ
        vertices, faces = marching_tetrahedra(sdf, grid)

        # 4. Vertex deformation (optional refinement)
        offsets = self.deform_mlp(vertex_features)
        vertices = vertices + offsets

        return vertices, faces
```

### 5.4 DMTet ì†ì‹¤ í•¨ìˆ˜

```python
L_dmtet = L_rgb + Î»_mask * L_mask + Î»_normal * L_normal + Î»_lap * L_laplacian

# RGB ì†ì‹¤ (ë Œë”ë§ ì¼ì¹˜)
L_rgb = ||render(mesh) - I_gt||_1

# Mask ì†ì‹¤ (ì‹¤ë£¨ì—£)
L_mask = BCE(silhouette(mesh), M_gt)

# Normal ì†ì‹¤ (í‘œë©´ ë¶€ë“œëŸ¬ì›€)
L_normal = ||n_pred - n_gt||_2

# Laplacian ì •ê·œí™” (ë©”ì‰¬ ë¶€ë“œëŸ¬ì›€)
L_laplacian = ||Î”v||_2  # ì´ì›ƒ ì •ì ê³¼ì˜ ì°¨ì´ ìµœì†Œí™”
```

> **Implementation Status**: DMTet Stage 2ëŠ” í˜„ì¬ ë¯¸êµ¬í˜„ (configë§Œ ì •ì˜, `train.py`ì—ì„œ skip). NeRF Stage 1ë§Œìœ¼ë¡œ ì´ë¯¸ì§€ ë Œë”ë§ ë° í¬ì¦ˆ ì¶”ì • ê°€ëŠ¥. ìƒì„¸: [Paper vs Implementation Audit](reports/260208_paper_vs_implementation_audit.md#5-dmtet-stage-2-analysis)

---

## 6. í•™ìŠµ ì„¤ì • (Paper)

### 6.1 í•˜ë“œì›¨ì–´ ìš”êµ¬ì‚¬í•­

| Component | Specification |
|-----------|---------------|
| GPU | NVIDIA RTX 3090 (24GB) ì´ìƒ |
| RAM | 32GB ì´ìƒ |
| Storage | 100GB+ (í•©ì„± ë°ì´í„°) |

### 6.2 í•™ìŠµ íŒŒë¼ë¯¸í„° (Table A3)

| Stage | Parameter | Value |
|-------|-----------|-------|
| **Avatar** | Iterations | 400,000 |
| | Learning Rate | 1e-3 |
| | Image Size | 800Ã—800 |
| | Frames | 800 |
| | Cameras | 8 |
| **Synthetic** | Scenes | 12,000 |
| | Views/Scene | 64 |
| | Image Size | 378Ã—378 |
| **NeRF** | Epochs | 60 |
| | Batch Size | 4 |
| | Learning Rate | 1e-4 |
| **DMTet** | Epochs | 100 |
| | Grid Resolution | 128 |
| | Learning Rate | 1e-4 |

### 6.3 ì†ì‹¤ ê°€ì¤‘ì¹˜

```python
# Avatar Training
loss_weights = {
    'l1': 1.0,
    'ssim': 0.2,
    'lpips': 0.1,
}

# NeRF Stage
loss_weights = {
    'rgb': 1.0,
    'depth': 0.1,
    'mask': 0.5,
}

# DMTet Stage
loss_weights = {
    'rgb': 1.0,
    'mask': 1.0,
    'normal': 0.1,
    'laplacian': 0.01,
}
```

### 6.4 ì˜ˆìƒ í•™ìŠµ ì‹œê°„

| Stage | Time (RTX 3090) |
|-------|-----------------|
| Avatar Training | 24-48 hours |
| Synthetic Generation | 2-4 hours |
| NeRF Training | 8-12 hours |
| DMTet Training | 16-24 hours |
| **Total** | **~50-88 hours** |

---

## 7. ì¶”ë¡  (Inference)

```python
# ë‹¨ì•ˆ ì´ë¯¸ì§€ì—ì„œ 3D ë©”ì‰¬ ì¶”ì¶œ
def inference(model, image, camera_params):
    """
    Args:
        image: [1, 3, H, W] - ì…ë ¥ ì´ë¯¸ì§€
        camera_params: dict - ì¹´ë©”ë¼ íŒŒë¼ë¯¸í„°

    Returns:
        mesh: trimesh.Trimesh - 3D ë©”ì‰¬
        novel_views: list - ìƒˆë¡œìš´ ì‹œì  ë Œë”ë§
    """
    with torch.no_grad():
        # 1. NeRF encoding
        triplane = model.encode(image)

        # 2. DMTet mesh extraction
        vertices, faces = model.extract_mesh(triplane)

        # 3. Novel view synthesis
        novel_views = []
        for view_camera in sample_cameras(num_views=8):
            rendered = model.render(triplane, view_camera)
            novel_views.append(rendered)

    return trimesh.Trimesh(vertices, faces), novel_views
```

---

## ì°¸ê³ ë¬¸í—Œ

1. MoReMouse: 3D Reconstruction of Laboratory Mice from Monocular RGB Images (2024)
2. 3D Gaussian Splatting for Real-Time Radiance Field Rendering (SIGGRAPH 2023)
3. Deep Marching Tetrahedra (NeurIPS 2021)
4. Instant Neural Graphics Primitives (SIGGRAPH 2022)
5. MAMMAL: Multi-Animal Articulated Model for 3D Animal reconstruction (2023)

---

## Related Documents

- [Refactoring Plan (2026-02-08)](refactoring/260208_refactoring_plan.md) â€” 3-phase code cleanup plan
- [Refactoring Report (2026-02-08)](refactoring/260208_refactoring_report.md) â€” Detailed results and metrics
- [Coordinate Alignment Analysis](reports/251213_moremouse_coordinate_alignment_analysis.md) â€” Y-up â†’ Z-up transform rationale
- [Gaussian Avatar Paper Comparison](reports/251212_gaussian_avatar_paper_comparison.md)
- [GPU05 Pipeline Guide](guides/gpu05_pipeline_guide.md)

### Shared Utility Modules (added 2026-02-08)

| Module | Purpose |
|--------|---------|
| `src/utils/transforms.py` | Coordinate constants, Y-upâ†’Z-up transforms, projection |
| `src/utils/geometry.py` | 22-keypoint definitions, extraction, skeleton drawing |
| `src/utils/avatar_visualization.py` | Debug visualization helpers |

---

*ë¬¸ì„œ ìƒì„±ì¼: 2024-12-09 | ìµœì¢… ìˆ˜ì •: 2026-02-08*
*MoReMouse Implementation v1.0*
