---
date: 2025-12-10
context_name: "2_Research"
tags: [ai-assisted, moremouse, 3d-reconstruction, gaussian-splatting, nerf, mouse-reconstruction]
project: moremouse
status: completed
generator: ai-assisted
generator_tool: claude-code
---

# MoReMouse 2ë‹¨ê³„ íŒŒì´í”„ë¼ì¸ ì„¤ê³„ ë° êµ¬í˜„ ì—°êµ¬

## ê¸°ë³¸ ì •ë³´

| í•­ëª© | ë‚´ìš© |
|------|------|
| **ë‚ ì§œ** | 2025-12-10 |
| **ì—°êµ¬ ì£¼ì œ** | ìƒì¥ 6-view ì˜ìƒ ë°ì´í„°ë¥¼ í™œìš©í•œ ë‹¨ì•ˆ(monocular) 3D ì¬êµ¬ì„± íŒŒì´í”„ë¼ì¸ |
| **í•µì‹¬ ëª©í‘œ** | MoReMouse ë…¼ë¬¸ì˜ 2ë‹¨ê³„ íŒŒì´í”„ë¼ì¸ ì„¤ê³„ ë° ì™„ì „ êµ¬í˜„ |
| **ì°¸ì¡° ë…¼ë¬¸** | [MoReMouse: Monocular Reconstruction of Laboratory Mouse](https://arxiv.org/abs/2507.04258) |

---

## 1. ë°°ê²½ ë° ë™ê¸° (Background & Motivation)

### 1.1 ë¬¸ì œ ì •ì˜

ë‹¨ì•ˆ ì´ë¯¸ì§€(monocular image)ì—ì„œ 3D ì¬êµ¬ì„±ì€ ë³¸ì§ˆì ìœ¼ë¡œ **ill-posed problem**ì´ë‹¤:
- ê¹Šì´ ì •ë³´ì˜ ëª¨í˜¸ì„± (depth ambiguity)
- ê°€ë ¤ì§„ ì˜ì—­ (occlusion) ì²˜ë¦¬ ì–´ë ¤ì›€
- íŠ¹íˆ ìƒì¥ëŠ” í…ìŠ¤ì²˜ê°€ ê· ì¼í•˜ê³ (C57BL/6 mice), ë¹„ê°•ì²´ ë³€í˜•(non-rigid deformation)ì´ ì‹¬í•¨

### 1.2 ì„ í–‰ ì—°êµ¬ì™€ì˜ ê´€ê³„

| ê¸°ìˆ  | ì—­í•  |
|------|------|
| **MAMMAL** (Dunn et al., 2021) | 140 ê´€ì ˆ ìƒì¥ body model, 13,059 vertices |
| **3D Gaussian Splatting** (SIGGRAPH 2023) | ì‹¤ì‹œê°„ ë Œë”ë§ ê°€ëŠ¥í•œ 3D í‘œí˜„ |
| **DINOv2** | Self-supervised vision features (768-dim) |
| **DMTet** (NeurIPS 2021) | Differentiable mesh extraction |

### 1.3 í•µì‹¬ ì•„ì´ë””ì–´

**ë¬¸ì œ**: ë‹¨ì•ˆ ì´ë¯¸ì§€ â†’ 3D ì§ì ‘ í•™ìŠµì€ GT ë°ì´í„° ë¶€ì¡±ìœ¼ë¡œ ì–´ë ¤ì›€

**í•´ê²°ì±…**: 2ë‹¨ê³„ íŒŒì´í”„ë¼ì¸
1. Multi-view ë°ì´í„°ë¡œ photorealistic avatar í•™ìŠµ
2. Avatarë¡œ ëŒ€ê·œëª¨ í•©ì„± ë°ì´í„° ìƒì„± â†’ ë‹¨ì•ˆâ†’3D ë„¤íŠ¸ì›Œí¬ í•™ìŠµ

---

## 2. ë°©ë²•ë¡  (Methodology)

### 2.1 ì „ì²´ íŒŒì´í”„ë¼ì¸ ì•„í‚¤í…ì²˜

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          MoReMouse 2-Stage Pipeline                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                        STAGE 1: Data Engine                          â”‚   â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚  Multi-view Videos      Gaussian Avatar       Synthetic Dataset      â”‚   â”‚
â”‚  â”‚  (6 cameras)            (AGAM)                (12K scenes)           â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚   â”‚
â”‚  â”‚  â”‚ ğŸ­ ğŸ­ ğŸ­â”‚  â”€â”€â”€â”€â”€â”€â”€â–¶ â”‚ â—‹â—‹â—‹â—‹â—‹â—‹  â”‚  â”€â”€â”€â”€â”€â”€â”€â–¶ â”‚ 768K images â”‚         â”‚   â”‚
â”‚  â”‚  â”‚   Ã—6    â”‚  400K iter â”‚ 13,059  â”‚  random   â”‚ + poses     â”‚         â”‚   â”‚
â”‚  â”‚  â”‚ views   â”‚           â”‚ Gaussiansâ”‚  poses    â”‚ + cameras   â”‚         â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                      â”‚                                       â”‚
â”‚                                      â–¼                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                       STAGE 2: Model Training                        â”‚   â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â”‚  Input Image        Triplane         NeRF            DMTet           â”‚   â”‚
â”‚  â”‚  [378Ã—378]          Features         Rendering       Mesh            â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚   â”‚
â”‚  â”‚  â”‚         â”‚ DINOv2â”‚ XY XZ YZâ”‚ MLP  â”‚ Volume  â”‚ SDF â”‚  Final  â”‚      â”‚   â”‚
â”‚  â”‚  â”‚   ğŸ­    â”‚â”€â”€â”€â”€â”€â”€â–¶â”‚ â”Œâ”â”Œâ”â”Œâ”  â”‚â”€â”€â”€â”€â”€â–¶â”‚ Render  â”‚â”€â”€â”€â”€â–¶â”‚  Mesh   â”‚      â”‚   â”‚
â”‚  â”‚  â”‚         â”‚ 768-d â”‚ â””â”˜â””â”˜â””â”˜  â”‚      â”‚ 128 pts â”‚     â”‚  + RGB  â”‚      â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚   â”‚
â”‚  â”‚                                                                       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 Stage 1: Gaussian Mouse Avatar (AGAM)

#### ëª©ì 
Multi-view ë¹„ë””ì˜¤ì—ì„œ photorealistic ìƒì¥ ì•„ë°”íƒ€ í•™ìŠµ

#### ì…ë ¥ ë°ì´í„°
- **ë°ì´í„°ì…‹**: markerless_mouse_1 (Dunn et al., 2021)
- **ì¹´ë©”ë¼**: 6-view ë™ê¸°í™” ë¹„ë””ì˜¤
- **í”„ë ˆì„**: 800 frames (8000 í”„ë ˆì„ì—ì„œ ê· ë“± ìƒ˜í”Œë§)
- **ì´ë¯¸ì§€ í¬ê¸°**: 800Ã—800

#### ì•„í‚¤í…ì²˜
```python
class GaussianAvatar:
    """UV ê¸°ë°˜ Gaussian Splatting"""

    # ì •ì ë‹¹ 1ê°œ Gaussian â†’ ì´ 13,059ê°œ
    Parameters per Gaussian:
    - position_offset: [V, 3]  # ë©”ì‰¬ ì •ì  ê¸°ì¤€ ì˜¤í”„ì…‹
    - color: [V, 3]            # RGB
    - opacity: [V, 1]          # ë¶ˆíˆ¬ëª…ë„
    - scale: [V, 3]            # Gaussian í¬ê¸°
    - rotation: [V, 4]         # Quaternion
```

#### Linear Blend Skinning (LBS)
í¬ì¦ˆì— ë”°ë¼ Gaussian ìœ„ì¹˜ ë³€í˜•:
```
v' = Î£ w_j Â· T_j Â· v
```
- `w_j`: skinning weight (ì •ì ì´ jë²ˆì§¸ ê´€ì ˆì— ì˜í–¥ë°›ëŠ” ì •ë„)
- `T_j`: jë²ˆì§¸ ê´€ì ˆì˜ 4Ã—4 ë³€í™˜ í–‰ë ¬

#### ë Œë”ë§ (gsplat)
```python
rendered = rasterization(
    means=positions,      # [13059, 3]
    quats=rotations,      # [13059, 4]
    scales=scales,        # [13059, 3]
    opacities=opacities,  # [13059, 1]
    colors=colors,        # [13059, 3]
    viewmats=camera,      # [4, 4]
    Ks=intrinsics,        # [3, 3]
)
```

#### í•™ìŠµ ì„¤ì •
| íŒŒë¼ë¯¸í„° | ê°’ |
|----------|-----|
| Iterations | 400,000 |
| Learning Rate | 1e-3 |
| Loss | L1 + SSIM + LPIPS |
| Auto-resume | âœ… ì§€ì› |

### 2.3 Stage 2: MoReMouse Network

#### 2.3.1 DINOv2 Encoder (Frozen)

```python
encoder = dinov2_vitb14  # ViT-B/14
# Input: [B, 3, 378, 378]
# Output: [B, 768, 27, 27] patch features
```

#### 2.3.2 Triplane Generator (Paper Table A3)

```python
class TriplaneGenerator:
    # 12-layer Transformer decoder
    # Flash Attention: O(n) memory

    Input:  [B, 729, 768]      # DINOv2 features
    Queries: [64Ã—64, 512]      # Learnable
    Output: [B, 3, 80, 128, 128]  # XY, XZ, YZ planes
```

#### 2.3.3 NeRF Decoder

```python
class TriplaneDecoder:
    # 10 shared hidden layers (64 neurons)

    For each 3D point (x, y, z):
        f_xy = bilinear_sample(planes[0], x, y)
        f_xz = bilinear_sample(planes[1], x, z)
        f_yz = bilinear_sample(planes[2], y, z)
        f = f_xy + f_xz + f_yz

        density, color, embedding = MLP(f)
```

#### 2.3.4 Volume Rendering

```python
def volume_render(density, color, z_vals):
    # 128 samples per ray
    alpha = 1 - exp(-density * delta_t)
    T = cumprod(1 - alpha)
    weights = T * alpha

    rgb = sum(weights * color)
    depth = sum(weights * z_vals)
    return rgb, depth
```

### 2.4 2-Stage Training

| Stage | Epochs | ëª©ì  |
|-------|--------|------|
| **NeRF** | 60 | Volumetric renderingìœ¼ë¡œ ë¶€ë“œëŸ¬ìš´ gradient ì „íŒŒ |
| **DMTet** | 100 | Explicit surface ì¶”ì¶œë¡œ geometric detail í–¥ìƒ |

### 2.5 ì†ì‹¤ í•¨ìˆ˜

```python
L_total = Î»_mseÂ·L_mse + Î»_lpipsÂ·L_lpips + Î»_maskÂ·L_mask
        + Î»_smoothÂ·L_smooth + Î»_depthÂ·L_depth + Î»_geoÂ·L_geo
```

| Loss | Weight (Î») | ì—­í•  |
|------|------------|------|
| MSE | 1.0 | Pixel-wise RGB reconstruction |
| LPIPS | 1.0 | Perceptual similarity (VGG) |
| Mask | 0.3 | Binary cross-entropy (opacity) |
| Smooth L1 | 0.2 | Large discrepancy penalty |
| Depth | 0.2 | Scale-invariant depth |
| Geodesic | 0.1 | Embedding consistency |

---

## 3. ì£¼ìš” ê²°ê³¼ (Key Findings/Results)

### 3.1 êµ¬í˜„ ì™„ë£Œ ìƒíƒœ

| Category | Status | Components |
|----------|--------|------------|
| **Models** | âœ… 100% | GaussianAvatar, MouseBodyModel, TriplaneGenerator, MoReMouse |
| **Data Loaders** | âœ… 100% | SyntheticDataset, MAMMALMultiviewDataset, VideoReader |
| **Loss Functions** | âœ… 100% | MSE, LPIPS, SSIM, Mask, Depth, Geodesic |
| **Scripts** | âœ… 100% | train, inference, evaluate, generate_synthetic_data, run_pipeline |
| **Configs** | âœ… 100% | model, data, train, avatar (Hydra-based) |

### 3.2 í•µì‹¬ êµ¬í˜„ ëª¨ë“ˆ

```
src/
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ mouse_body.py        # MAMMAL 140-joint body model
â”‚   â”œâ”€â”€ gaussian_avatar.py   # AGAM + Trainer (400K iter)
â”‚   â”œâ”€â”€ geodesic_embedding.py # Heat method geodesic
â”‚   â”œâ”€â”€ triplane.py          # Transformer + Decoder + Upsampler
â”‚   â””â”€â”€ moremouse_net.py     # DINOv2 + Triplane + NeRF
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ dataset.py           # SyntheticDataset, RealDataset
â”‚   â”œâ”€â”€ mammal_loader.py     # Multi-view loader (video/image)
â”‚   â””â”€â”€ transforms.py        # Data augmentation
â”œâ”€â”€ losses/
â”‚   â”œâ”€â”€ reconstruction.py    # MSE, L1, SSIM, LPIPS
â”‚   â”œâ”€â”€ mask.py, depth.py    # Mask/Depth losses
â”‚   â””â”€â”€ combined.py          # MoReMouseLoss
â””â”€â”€ utils/
    â”œâ”€â”€ logging.py           # Console/file logging
    â”œâ”€â”€ metrics.py           # PSNR, SSIM, LPIPS
    â””â”€â”€ visualization.py     # Multi-view grid, mesh
```

### 3.3 ê¸°ìˆ ì  íŠ¹ì§•

| Feature | Implementation |
|---------|----------------|
| **Flash Attention** | `F.scaled_dot_product_attention` â†’ O(n) memory |
| **Chunked Rendering** | 4096 rays/chunk â†’ GPU memory efficient |
| **Video Reader** | LRU cache (100 frames) â†’ íš¨ìœ¨ì  video access |
| **Auto-resume** | Checkpoint ìë™ ê°ì§€ ë° resume ì§€ì› |
| **Data Format** | Video (mp4) + Image í˜•ì‹ ìë™ ê°ì§€ |

### 3.4 ì˜ˆìƒ ì„±ëŠ¥ (Paper ê¸°ì¤€)

| Dataset | PSNR â†‘ | SSIM â†‘ | LPIPS â†“ |
|---------|--------|--------|---------|
| Synthetic | 22.03 | 0.966 | 0.053 |
| Real | 18.42 | - | - |

---

## 4. ë¶„ì„ ë° ë…¼ì˜ (Analysis & Discussion)

### 4.1 íŒŒì´í”„ë¼ì¸ ì„¤ê³„ ê·¼ê±°

**ì™œ 2ë‹¨ê³„ íŒŒì´í”„ë¼ì¸ì¸ê°€?**

1. **ë°ì´í„° ë¬¸ì œ í•´ê²°**: ì‹¤ì œ GT 3D mesh ë°ì´í„° íšë“ ì–´ë ¤ì›€ â†’ Avatarë¡œ í•©ì„± ë°ì´í„° ìƒì„±
2. **ë„ë©”ì¸ ê°­ ìµœì†Œí™”**: Multi-viewë¡œ í•™ìŠµëœ avatarëŠ” ì‹¤ì œ ìƒì¥ ì™¸ê´€ì„ ì˜ ë³µì›
3. **í™•ì¥ì„±**: ë‹¤ì–‘í•œ í¬ì¦ˆ/ë·°í¬ì¸íŠ¸ ì¡°í•© ìƒì„± ê°€ëŠ¥ (12K scenes Ã— 64 views = 768K images)

### 4.2 êµ¬í˜„ ê³¼ì •ì˜ ì£¼ìš” ê²°ì •

| ê²°ì • ì‚¬í•­ | ì„ íƒ | ì´ìœ  |
|-----------|------|------|
| Gaussian per vertex | 1ê°œ | 13,059ê°œë¡œ ì¶©ë¶„í•œ í‘œí˜„ë ¥ |
| Triplane resolution | 128Ã—128 | Memory vs quality ê· í˜• |
| Query resolution | 64Ã—64 â†’ Upsample | Flash Attention ë©”ëª¨ë¦¬ íš¨ìœ¨ |
| NeRF samples | 128 per ray | Paper specification |

### 4.3 ì‹œì‚¬ì 

1. **Avatar í’ˆì§ˆì´ ìµœì¢… ì„±ëŠ¥ ê²°ì •**: Stage 1ì˜ avatar í’ˆì§ˆì´ í•©ì„± ë°ì´í„° í’ˆì§ˆ ê²°ì •
2. **Flash Attention í•„ìˆ˜**: 128Ã—128 triplaneì€ ê¸°ì¡´ attentionìœ¼ë¡œ OOM ë°œìƒ
3. **Video format ì§€ì› ì¤‘ìš”**: MAMMAL nerf format (mp4)ì™€ image format ëª¨ë‘ ì§€ì› í•„ìš”

---

## 5. ë¯¸ê²° ê³¼ì œ (Open Questions)

### 5.1 í˜„ì¬ í•œê³„

| í•œê³„ | ì„¤ëª… | ìš°ì„ ìˆœìœ„ |
|------|------|----------|
| **Avatar í•™ìŠµ ë¯¸ì™„ë£Œ** | 400K iteration í•™ìŠµ í•„ìš” (ì•½ 24-48ì‹œê°„) | High |
| **í•©ì„± ë°ì´í„° ë¯¸ìƒì„±** | 6000 frames Ã— 64 views ìƒì„± í•„ìš” | High |
| **DMTet ê²€ì¦ ë¯¸ì™„ë£Œ** | Kaolin ì˜ì¡´ì„±ìœ¼ë¡œ ë³„ë„ í™˜ê²½ í•„ìš” | Medium |
| **Real data í‰ê°€** | ì‹¤ì œ ë°ì´í„°ì…‹ evaluation ë¯¸ì§„í–‰ | Medium |

### 5.2 ì¶”ê°€ íƒìƒ‰ í•„ìš”

1. **Avatar í•™ìŠµ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹**
   - Learning rate schedule
   - Loss weight ì¡°ì • (L1 vs SSIM vs LPIPS ë¹„ìœ¨)

2. **í•©ì„± ë°ì´í„° ë‹¤ì–‘ì„±**
   - Pose sampling ì „ëµ (uniform vs importance sampling)
   - Camera placement ì „ëµ

3. **ì¼ë°˜í™” ì„±ëŠ¥**
   - ë‹¤ë¥¸ ìƒì¥ ê°œì²´ì— ëŒ€í•œ ì„±ëŠ¥
   - Out-of-distribution poseì— ëŒ€í•œ robustness

---

## 6. ë‹¤ìŒ ë‹¨ê³„ (Next Steps)

### ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥
```bash
# 1. Avatar í•™ìŠµ ì‹œì‘ (gpu05)
CUDA_VISIBLE_DEVICES=1 python scripts/run_pipeline.py \
    --stage avatar \
    --data-dir /home/joon/data/markerless_mouse_1_nerf \
    --avatar-iterations 400000

# 2. í•©ì„± ë°ì´í„° ìƒì„±
python scripts/run_pipeline.py --stage synthetic \
    --avatar-checkpoint checkpoints/avatar/avatar_final.pt \
    --num-frames 6000 --num-views 64

# 3. MoReMouse í•™ìŠµ
python scripts/run_pipeline.py --stage train \
    --nerf-epochs 60 --dmtet-epochs 100
```

### ì¶”í›„ ì‘ì—…
- [ ] Avatar í•™ìŠµ ì™„ë£Œ ë° í’ˆì§ˆ ê²€ì¦
- [ ] í•©ì„± ë°ì´í„° ìƒì„± ë° í’ˆì§ˆ í™•ì¸
- [ ] Full training ì‹¤í–‰ (NeRF 60 + DMTet 100 epochs)
- [ ] Real data evaluation
- [ ] ë…¼ë¬¸ ìˆ˜ì¹˜ ì¬í˜„ í™•ì¸

---

## ì°¸ê³  ë¬¸í—Œ

1. MoReMouse: Monocular Reconstruction of Laboratory Mouse (arXiv:2507.04258, 2025)
2. 3D Gaussian Splatting for Real-Time Radiance Field Rendering (SIGGRAPH 2023)
3. Deep Marching Tetrahedra (NeurIPS 2021)
4. MAMMAL: Multi-Animal Articulated Model (2021)
5. DINOv2: Learning Robust Visual Features (CVPR 2024)

---

## Git Commits (Recent)

```
add9ad0 feat(avatar): add resume training and auto-checkpoint detection
2708646 fix(data): handle None pose in MAMMAL dataloader
d065fe5 feat(data): add video format support for MAMMAL multi-view data
1b5d033 fix: gsplat render fail
759319e feat: modules baseline
```

---

*Generated: 2025-12-10*
*MoReMouse 2-Stage Pipeline Research Note*
